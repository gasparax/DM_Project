{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daab5335",
   "metadata": {},
   "source": [
    "<b>Data mining Project - 2021/22</b><br/>\n",
    "<span>\n",
    "<b>Authors:</b> Mariagiovanna Rotundo (560765), Nunzio Lopardo (600005)</a> and Renato Eschini (203021)<br/>\n",
    "<b>Group:</b>3<br/>\n",
    "<b>Release date:</b> 26/12/2021\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0fe57",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cfe40a",
   "metadata": {},
   "source": [
    "In this notebook we use different classificators for the classification task and we evaluate the performaces. The used dataset is the dataset of player created in the preparation notebook. \n",
    "Sunce the dataset for train and test are imbalanced, for the classification task 3 different approaches are evaluated:\n",
    "1. the classification is done on the train and testset without considering the imbalance\n",
    "2. the classification is done on the train and test given different weight to the 2 classes (high rank and low rank)\n",
    "3. the classification is done on oversapled train and testset using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea563e",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beddf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pydotplus \n",
    "import statistics \n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import Image  \n",
    "import scikitplot as skplt\n",
    "import wittgenstein as lw\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.spatial.distance import pdist,  squareform\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, classification_report, plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay # For Model evaluation\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008b8d5",
   "metadata": {},
   "source": [
    "**Loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574186fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load of the data\n",
    "DATASET_DIR = \"dataset\" + os.path.sep\n",
    "#index_col=False say to not use the first column as ID\n",
    "df_players = pd.read_csv('players.csv', sep=',', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf110a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_players.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad539d",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201f798",
   "metadata": {},
   "source": [
    "In this section are defined the functions used in the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fae0f",
   "metadata": {},
   "source": [
    "**function to discretize categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data(dataset, variables): #mapping categorical into numerical\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d96c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics computed on the test set\n",
    "def report_scores(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['low', 'high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics computed on the test set\n",
    "def compare_scores(models,test_set, test_label):\n",
    "    for model in models.keys():\n",
    "        print('\\t\\t\\t' + model)\n",
    "        test_pred =  models[model].predict(test_set)\n",
    "        report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea869650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_errors(test_label, test_pred):\n",
    "    spotted_errors = []\n",
    "    for i in range(len(test_label)):\n",
    "        if(test_label.array[i]!= test_pred[i]):\n",
    "            spotted_errors.append('darkred')\n",
    "        else:\n",
    "            spotted_errors.append('darkgray')\n",
    "    return spotted_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e6d95",
   "metadata": {},
   "source": [
    "**Plot the neural network training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df32bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nn_training_history(history):\n",
    "    from matplotlib.pyplot import figure\n",
    "    fig, (acc_plot, loss_plot) = plt.subplots(2, figsize=(15, 6), dpi=240)\n",
    "    fig.suptitle('Accuracy and Loss trends')\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    acc_plot.plot(epochs, acc, label='Training Acc')\n",
    "    acc_plot.plot(epochs, val_acc, label='Validation Acc')\n",
    "    acc_plot.legend(loc='best')\n",
    "    acc_plot.set_ylabel('Accuracy')\n",
    "    acc_plot.set_ylim([0,1])\n",
    "    acc_plot.grid(True)\n",
    "    loss_plot.plot(epochs, loss, label='Trining Loss')\n",
    "    loss_plot.plot(epochs, val_loss, label='Validation Loss')\n",
    "    loss_plot.legend(loc='best')\n",
    "    loss_plot.set_ylabel('Loss')\n",
    "    loss_plot.set_ylim([0,1])\n",
    "    loss_plot.set_xlabel('Epochs')\n",
    "    loss_plot.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a640d8",
   "metadata": {},
   "source": [
    "**Scatter plot comparison real/classified/misclassified data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_pred_data(test_set, test_label, test_pred, classifier_name, x, y):\n",
    "    fig, (test_true_plt, test_pred_plt, errors_plt) = plt.subplots(1,3, figsize=(18,6), sharey=True)\n",
    "    title = classifier_name + ' | Real vs Predicted labels'\n",
    "    plt.suptitle(title)\n",
    "    test_true_plt.set_title('True Label')\n",
    "    test_true_plt.scatter(test_set[x].values, test_set[y].values, c=test_label.values, s=25, cmap='viridis')\n",
    "    test_pred_plt.set_title('Predicted Label')\n",
    "    test_pred_plt.scatter(test_set[x].values, test_set[y].values, c=test_pred, s=25, cmap='viridis')\n",
    "    spotted_errors = spot_errors(test_label, test_pred)\n",
    "    errors_plt.set_title('Misclassification')\n",
    "    errors_plt.scatter(test_set[x].values, test_set[y].values, c=spotted_errors, s=25, cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb5fbe",
   "metadata": {},
   "source": [
    "**Print the dataset composition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_composition(train_set, train_labels, test_set, test_labels):\n",
    "    print(f\"{len(train_labels)} training samples:\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 0])} samples for the class Low Rank\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 1])} samples for the class High Rank\")\n",
    "    print(f\"\\n{len(test_labels)} test samples:\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 0])} samples for the class Low Rank\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 1])} samples for the class High Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24056fdd",
   "metadata": {},
   "source": [
    "**Plot the ROC curve and compute the AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(model, test_set, test_label, test_pred, classifier_name):\n",
    "    x_test = np.reshape(test_set.values, (len(test_set), 1, len(test_set.columns)))\n",
    "    y_pred_keras = model.predict(x_test).ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(test_label, test_pred)\n",
    "    auc_area = auc(fpr, tpr)\n",
    "    label_name = classifier_name + '(area = {:.3f})'.format(auc_area)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label=label_name)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f983fa7",
   "metadata": {},
   "source": [
    "**Plot used to compare multiple ROC curves and AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_roc_curves(models, test_set, test_label):\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "    for model in models.keys():  \n",
    "        if (\"knn\" in model):\n",
    "            knn_test_set = test_set.drop(columns=['sex_num', 'hand_num'])\n",
    "            pred = models[model].predict(knn_test_set)\n",
    "        else:     \n",
    "            pred = models[model].predict(test_set)\n",
    "    \n",
    "        fpr, tpr, _ = roc_curve(test_label, pred)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        result_table = result_table.append({'classifiers':model,\n",
    "                                    'fpr':fpr, \n",
    "                                    'tpr':tpr, \n",
    "                                    'auc':auc_score}, ignore_index=True)\n",
    "    result_table.set_index('classifiers', inplace=True)\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    for i in result_table.index:\n",
    "        plt.plot(result_table.loc[i]['fpr'], \n",
    "                 result_table.loc[i]['tpr'], \n",
    "                 label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "\n",
    "    plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "    plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
    "\n",
    "    plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "    plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5ea42",
   "metadata": {},
   "source": [
    "**Plot confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_mx(test_label, test_pred):\n",
    "    cm = confusion_matrix(test_label, test_pred, labels=test_label.unique())\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= ['low', 'high'])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab265d",
   "metadata": {},
   "source": [
    "**Plot multiple confusion matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b72def",
   "metadata": {},
   "source": [
    "Given a dictionary of trained classifiers ({classifier_name: model}) plots the confusion matrix for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models_list, classifier_name, test_set, test_label):\n",
    "    i = 0\n",
    "    col_count = len(train_set.columns)\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=len(models_list), figsize=(18,6), sharey=True)\n",
    "    title = classifier_name + ' | Confusion Matrix comparison'\n",
    "    plt.suptitle(title)\n",
    "    for model in models_list.keys():\n",
    "        test_pred =  models_list[model].predict(test_set)\n",
    "        cm=confusion_matrix(test_label,test_pred)\n",
    "        sns.heatmap(cm, ax=axs[i], annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "        axs[i].set_title(model)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600fca10",
   "metadata": {},
   "source": [
    "**Function to normalize a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(df):\n",
    "    cols_to_norm = ['best_rank_points', 'w_tourney', 'tot_minutes', 'sv1st', 'sv1st_win', 'sv2nd_win', \n",
    "           'df', 'ace', 'bpS', 'wmatch', 'lmatch', 'nmatch', 'n_tourney']\n",
    "    df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc8d25",
   "metadata": {},
   "source": [
    "## Data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3659500",
   "metadata": {},
   "source": [
    "Selection of the colmuns that will be used to define train and testset and to define the labels. To establish if a player is high or low ranked we use the \"best_rank\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19034b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_players[['sex', 'hand','best_rank','best_rank_points', 'w_tourney', 'tot_minutes', 'sv1st', 'sv1st_win', 'sv2nd_win', \n",
    "           'df', 'ace', 'bpS', 'wmatch', 'lmatch', 'nmatch', 'n_tourney']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576769e",
   "metadata": {},
   "source": [
    "Discretization of sex and hand values since they are categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'hand']\n",
    "df_filtered = discretize_data(df_filtered, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5453a06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(columns=['sex', 'hand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7c741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36cded",
   "metadata": {},
   "source": [
    "We consider as high ranked the players that are in the first 50 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15556d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']<=threshold)), 'ranked'] = 1 #high\n",
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']>threshold)), 'ranked'] = 0 #low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']<=threshold))].shape[0] #number of high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fe19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']>threshold))].shape[0] #number of low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9899a",
   "metadata": {},
   "source": [
    "255 players are considered high ranked and 4192 are considered low ranked. For the classification task we do not consider the players for which we cannot establish the rank using the best_rank value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2351e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = df_filtered[df_filtered['best_rank']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = df_classification.drop(columns=['best_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1148d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb816b2c",
   "metadata": {},
   "source": [
    "Creation of training set and test set and their labels. To creare these sets we mantain the same proportions between the 2 class and we use a test set smaller than the training (test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d763d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df_classification.pop('ranked')\n",
    "train_set, test_set, train_label, test_label = train_test_split(df_classification, label, stratify = label, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f817f1c",
   "metadata": {},
   "source": [
    "**Dataset normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_set = normalize_dataset(train_set)\n",
    "norm_test_set = normalize_dataset(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12d47e",
   "metadata": {},
   "source": [
    "**Dataset composition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d83c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dataset_composition(train_set, train_label, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127811b5",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e27f5c",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a767226",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c9ed3",
   "metadata": {},
   "source": [
    "**creation and fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, \n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)\n",
    "dt_models['dt_original'] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=list(train_set.columns),  \n",
    "                         class_names=['low', 'high'],  #[0, 1]\n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff12995",
   "metadata": {},
   "source": [
    "**prediction on train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77f38b",
   "metadata": {},
   "source": [
    "#### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e4c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#per il training set\n",
    "report_scores(train_label, train_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f763cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per il test set\n",
    "report_scores(test_label, test_pred_dt)\n",
    "#l'accuracy è un buon indicatore, è significativa se è maggiore dell'accuracy della majority class. in caso di \n",
    "#situazione unbalance anche la precision e la recall aiutano a capire quanti errori abbiamo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8581dc3",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb87971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the confusion matrix \n",
    "plot_confusion_mx(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec4b4c",
   "metadata": {},
   "source": [
    "**Example of plot with classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3251e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true labels - different colors for different class\n",
    "scatter_pred_data(test_set, test_label, test_pred_dt, 'Decision tree', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37603b50",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c60bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0541b0f",
   "metadata": {},
   "source": [
    "**creation and fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a719ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='sigmoid', C=0.5, gamma='scale', probability=True)\n",
    "svm.fit(train_set, train_label)\n",
    "svm_models['svm_original'] = svm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b3dc6",
   "metadata": {},
   "source": [
    "**prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cba226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_svm = svm.predict(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svm = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413ae61",
   "metadata": {},
   "source": [
    "**evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c848b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the performance of the model\n",
    "report_scores(test_label, test_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f36335",
   "metadata": {},
   "source": [
    "We can notice that this model classify all the players as low ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65339c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred_svm, 'SVM', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d91cb",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29d25b",
   "metadata": {},
   "source": [
    "The used rule-based method is RIPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890905c7",
   "metadata": {},
   "source": [
    "**creation and fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(train_set, train_label, pos_class=1)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcffc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and fit the rule-based model\n",
    "#this function requires only one dataset with the labels. \n",
    "#To do so, we concatenate the train_set and the train_label\n",
    "ripper = lw.RIPPER(k=grid_result.best_params_['k'], prune_size=grid_result.best_params_['prune_size'])\n",
    "datas = pd.concat([train_set, train_label], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3a44c",
   "metadata": {},
   "source": [
    "**obtained rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018587d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models['rb_original'] = ripper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1dee2b",
   "metadata": {},
   "source": [
    "**evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_train = ripper.predict(train_set)\n",
    "report_scores(train_label, ripper_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred = ripper.predict(test_set)\n",
    "report_scores(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd992e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier (test set)\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8036ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, ripper_pred, 'Rule based', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f686062",
   "metadata": {},
   "source": [
    "**prediction obtaining the used rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_reasons = ripper.predict(test_set, give_reasons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02de896",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [i for i,elem in enumerate(ripper_pred_reasons[0]) if elem == True]\n",
    "rules_used = [ripper_pred_reasons[1][elem] for i,elem in enumerate(indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rules_used) #high predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dff7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c5dae",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87cd458",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2211801",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3443c11",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c946e",
   "metadata": {},
   "source": [
    "**Train the Gaussain Naive Bayes classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a98ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model.fit(train_set, train_label)\n",
    "gnb_models['gnb_original'] = gnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5de5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = gnb_model.predict(test_set)\n",
    "print(classification_report(test_label, test_pred, target_names = ['low','high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312ff3c",
   "metadata": {},
   "source": [
    "The performance report reveals the low capacity of the GNB classifier to correctly classify the hig rank players. This is due to the highly imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bd7f1",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f7ffa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938e790",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "Adaboost is an ensemble learning algorithm that uses the boosting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setthe variables to make them easier to use\n",
    "X_train, X_test, y_train, y_test = train_set.values, test_set.values, train_label.values, test_label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c3e7b",
   "metadata": {},
   "source": [
    "##### Using DecisionTreeClassifier (default) as Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report score on test label\n",
    "report_scores(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "X_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6df772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report score on train label\n",
    "report_scores(train_label, X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89e80f",
   "metadata": {},
   "source": [
    "##### Using Support Vector Classifier as Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb045285",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(probability=True, kernel='linear')\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc =AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report score on test label\n",
    "report_scores(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the response for train dataset\n",
    "X_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report score on train label\n",
    "report_scores(train_label, X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d356a",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Is a class of ensemble methods specifically designed for decision trees. It combines the predictions made by multiple decision trees and outputs the class that is the mode of the class's output by individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "# Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(train_set,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred=clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report score on test label\n",
    "report_scores(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the response for train dataset\n",
    "X_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ddd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report score on train label\n",
    "report_scores(train_label, X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6c001",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f2473",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c820c",
   "metadata": {},
   "source": [
    "In the following list we will save all the trained Neural Network models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292e50c",
   "metadata": {},
   "source": [
    "**Define and compile the neural network model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4245c8f",
   "metadata": {},
   "source": [
    "Function that returns the defalut neural network model with initial weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn_model(optimizer = 'adam', activation='relu', dropout_rate=0.15, neurons=15, loss='binary_crossentropy'): #specify parameters so that we can do grid search\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(1, len(train_set.columns))),\n",
    "        tf.keras.layers.Dense(neurons, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(neurons, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),    \n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee94c6",
   "metadata": {},
   "source": [
    "Give a model and trainig set, this function train the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ce1ba",
   "metadata": {},
   "source": [
    "Best: 0.973970 using {'activation': 'relu', 'batch_size': 500, 'dropout_rate': 0.2, 'epochs': 100, 'loss': 'binary_crossentropy', 'neurons': 13, 'optimizer': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(model, train_set, train_label, epochs=60, batch_size=128,validation_split=0.2, verbose=False, class_weights=None):\n",
    "    x_train = np.reshape(train_set.values, (len(train_set), 1, len(train_set.columns)))\n",
    "    if class_weights is not None:\n",
    "        history = model.fit(x_train, train_label,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=validation_split,\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=verbose)\n",
    "    else:\n",
    "        history = model.fit(x_train, train_label,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=validation_split,\n",
    "                            verbose=verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = base_nn_model()\n",
    "nn_model, history = train_nn_model(nn_model, norm_train_set, train_label)\n",
    "nn_models['NN_original'] = nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109a915",
   "metadata": {},
   "source": [
    "Train the model using the original and normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40175bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34c0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_nn_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858aced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.reshape(norm_train_set.values, (len(norm_train_set), 1, len(train_set.columns)))\n",
    "train_pred = (nn_model.predict(x_train_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f79a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(norm_test_set.values, (len(norm_test_set), 1, len(norm_test_set.columns)))\n",
    "test_pred = (nn_model.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaea37e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a27b8",
   "metadata": {},
   "source": [
    "Given the trained NN model, let's look the cofusion matrix on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb899c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_label,test_pred)\n",
    "#il parametro fmt serve per evitare la notazione esponenziale dei numeri\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54943c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_pred_data(norm_test_set, test_label, test_pred, 'Neural Network', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560548a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_curve_plot(nn_model, norm_test_set, test_label, test_pred, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e283e7",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaab9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94458049",
   "metadata": {},
   "source": [
    "Fit and scoring the classifier using the function *GridSearchCV*, by sklearn, that automatically compute the best combination of parameters for the model training. Below are created the set of parameters for the KNN training that the function will use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2f479",
   "metadata": {},
   "source": [
    "For the KNN we need to remove the categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_set = train_set.drop(columns=['sex_num', 'hand_num'])\n",
    "knn_test_set = test_set.drop(columns=['sex_num', 'hand_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14025c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_metrics = ['euclidean', 'manhattan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9da18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_weights = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_algorithms = ['ball_tree', 'kd_tree', 'brute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5747837",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': k_range,\n",
    "    'metric': knn_metrics,\n",
    "    'algorithm': knn_algorithms,\n",
    "    'weights': knn_weights\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84023c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=10, scoring='accuracy')\n",
    "knn_grid.fit(knn_train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b46c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(knn_grid.best_score_))\n",
    "print('Parameters: ' + str(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec614fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**knn_grid.best_params_).fit(knn_train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_models['knn_original'] = knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5abf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred = knn.predict(knn_train_set)\n",
    "report_scores(train_label,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ad9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = knn.predict(knn_test_set)\n",
    "report_scores(test_label,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred, 'KNN', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3e101",
   "metadata": {},
   "source": [
    "As we know from the theory, the nearest neighbor classifiers can be biased by noise points that have oversized data values that can miss lead the classification task. The solution to this problem is normalization, in the following lines of code a normalized dataset is created using the *MinMaxScaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7843b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=10, scoring='accuracy')\n",
    "norm_knn_train_set = normalize_dataset(knn_train_set)\n",
    "norm_knn_test_set = normalize_dataset(knn_test_set)\n",
    "knn_grid.fit(norm_knn_train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(knn_grid.best_score_))\n",
    "print('Parameters: ' + str(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**knn_grid.best_params_).fit(norm_knn_train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8becc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred = knn.predict(norm_knn_train_set)\n",
    "report_scores(train_label,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cd948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = knn.predict(norm_knn_test_set)\n",
    "report_scores(test_label,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18aff1c",
   "metadata": {},
   "source": [
    "# Classification with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f2e57",
   "metadata": {},
   "source": [
    "Weights associated with classes in the form {class_label: weight}.\n",
    "\n",
    "The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as:\n",
    "\n",
    "$\\frac{n_{samples}}{(n_{classes}\\  *\\  np.bincount(y))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca905a1e",
   "metadata": {},
   "source": [
    "Using weights we can say that the examples of a given class are more important than examples of the other class. <br>\n",
    "To find the best weights for each classifier we do a grid search on a given list of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set weights\n",
    "weights = {0:1.0, 1:100.0} #0=low, 1 = high\n",
    "balance = [{0:0.8,1:3.5}, {0:1,1:5}, {0:1,1:10}, {0:1,1:15}, {0:1,1:20}, {0:1,1:50}, {0:1,1:100}, 'balanced']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1967c",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc09aa",
   "metadata": {},
   "source": [
    "**creation of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, class_weight=weights,\n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cca9c",
   "metadata": {},
   "source": [
    "#### choise of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "param_grid = dict(class_weight=balance)\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, class_weight=grid_result.best_params_['class_weight'],\n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)\n",
    "dt_models['dt_weighted'] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cce696",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=list(train_set.columns),  \n",
    "                         class_names=['low', 'high'],  #[0, 1]\n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734e333",
   "metadata": {},
   "source": [
    "**prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315440a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c03d1f",
   "metadata": {},
   "source": [
    "**evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aede62",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021165ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f468f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred_dt, 'Decision Tree', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394cf5e",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2400899",
   "metadata": {},
   "source": [
    "**creation of the model with fixed weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f646f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='scale', class_weight=weights)\n",
    "svm.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(train_set)\n",
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da100266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the performance of the model\n",
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874950fe",
   "metadata": {},
   "source": [
    "#### choise of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "param_grid = dict(class_weight=balance)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c39139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='scale', class_weight=grid_result.best_params_['class_weight'])\n",
    "svm.fit(train_set, train_label)\n",
    "svm_models['svm_weighted'] = svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d237f",
   "metadata": {},
   "source": [
    "**prediction and evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(train_set)\n",
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svm.predict(test_set)\n",
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308de8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee343cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred, 'SVM', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d810dc5",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c9917",
   "metadata": {},
   "source": [
    "**creation of the model and choose of weights and parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79794ecc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5], \"class_weight\": balance}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(train_set, train_label, pos_class=1)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper = lw.RIPPER(k=grid_result.best_params_['k'], prune_size=grid_result.best_params_['prune_size'])\n",
    "datas = pd.concat([train_set, train_label], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1, class_weight = grid_result.best_params_['class_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0a1bb",
   "metadata": {},
   "source": [
    "**get model (rules)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bed9e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd17b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models['rb_weighted'] = ripper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7e0df",
   "metadata": {},
   "source": [
    "**prediction and evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_train = ripper.predict(train_set)\n",
    "report_scores(train_label, ripper_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred = ripper.predict(test_set)\n",
    "report_scores(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c145dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea670e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, ripper_pred, 'Rule Based', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4a319",
   "metadata": {},
   "source": [
    "**rules used for predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_reasons = ripper.predict(test_set, give_reasons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94719e8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indexes = [i for i,elem in enumerate(ripper_pred_reasons[0]) if elem == True]\n",
    "rules_used = [ripper_pred_reasons[1][elem] for i,elem in enumerate(indexes)]\n",
    "rules_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f2afb",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca905dc2",
   "metadata": {},
   "source": [
    "Now let's re-run the neural network classifier using the weighted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45de42",
   "metadata": {},
   "source": [
    "#### choise of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ca7d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights_nn = {0: 0.75, 1: 3.5}\n",
    "class_weights = class_weight.compute_class_weight(class_weight = weights_nn,\n",
    "                                                 classes = np.unique(train_label),\n",
    "                                                 y = train_label)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1150bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_w = base_nn_model()\n",
    "nn_model_w, history = train_nn_model(nn_model_w, norm_train_set, train_label)\n",
    "nn_models['NN_weighted'] = nn_model_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65bcdc",
   "metadata": {},
   "source": [
    "Train the model using the original and normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939426e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_nn_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.reshape(norm_train_set.values, (len(norm_train_set), 1, len(norm_train_set.columns)))\n",
    "train_pred = (nn_model_w.predict(x_train_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3084b42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63395daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(norm_test_set.values, (len(norm_test_set), 1, len(norm_test_set.columns)))\n",
    "test_pred = (nn_model_w.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ad27f",
   "metadata": {},
   "source": [
    "Given the trained NN model, let's look the cofusion matrix on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171671fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_label,test_pred)\n",
    "#il parametro fmt serve per evitare la notazione esponenziale dei numeri\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e421231",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_pred_data(norm_test_set, test_label, test_pred, 'Neural Network', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1c991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_curve_plot(nn_model_w, norm_test_set, test_label, test_pred, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18890b7c",
   "metadata": {},
   "source": [
    "# Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcd4ae",
   "metadata": {},
   "source": [
    "We use SMOTE to apply oversampling to the 2 classes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(sampling_strategy=0.3)\n",
    "training, labels = oversample.fit_resample(train_set, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256f550",
   "metadata": {},
   "source": [
    "**Original Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562df2b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dataset_composition(train_set, train_label, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d91e6",
   "metadata": {},
   "source": [
    "**Dataset after oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c65488",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataset_composition(training, labels, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed2ace",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5315b",
   "metadata": {},
   "source": [
    "**new model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2505a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, \n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(training, labels)\n",
    "dt_models['dt_ov'] = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93568c",
   "metadata": {},
   "source": [
    "**prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779aff71",
   "metadata": {},
   "source": [
    "**evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fb11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred_dt, 'Decision Tree', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cbfa6",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc898bc",
   "metadata": {},
   "source": [
    "**new model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='sigmoid', gamma='scale')\n",
    "svm.fit(training, labels)\n",
    "svm_models['svm_ov'] = svm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693932f",
   "metadata": {},
   "source": [
    "**prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a16b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(train_set)\n",
    "test_pred = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25aba9",
   "metadata": {},
   "source": [
    "**evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dca09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred, 'SVM', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7bc12",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce22e7a",
   "metadata": {},
   "source": [
    "**new model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(training, labels, pos_class=1)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper = lw.RIPPER(k=grid_result.best_params_['k'], prune_size=grid_result.best_params_['prune_size'])\n",
    "datas = pd.concat([training, labels], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef5660",
   "metadata": {},
   "source": [
    "**model (rules)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb151edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models['rb_ov'] = ripper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c295ff",
   "metadata": {},
   "source": [
    "**prediction and evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8adf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_train = ripper.predict(train_set)\n",
    "report_scores(train_label, ripper_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3557a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred = ripper.predict(test_set)\n",
    "report_scores(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994be595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, ripper_pred, 'Rule based', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4c26b",
   "metadata": {},
   "source": [
    "### Gaussain Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dca3db",
   "metadata": {},
   "source": [
    "Gaussain Naive Bayes using the oversampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9019f",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6912a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07188b",
   "metadata": {},
   "source": [
    "**Train the Gaussain Naive Bayes classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model.fit(training, labels)\n",
    "gnb_models['gnb_ov'] = gnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe87a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = gnb_model.predict(test_set)\n",
    "print(classification_report(test_label, test_pred, target_names = ['low','high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f3f4fe",
   "metadata": {},
   "source": [
    "The performance report reveals the low capacity of the GNB classifier to correctly classify the hig rank players. This is due to the highly imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6865e",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69043dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label,test_pred)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b69168",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2620a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ov_train_set = normalize_dataset(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_ov = base_nn_model()\n",
    "nn_model_ov, history = train_nn_model(nn_model_ov, norm_ov_train_set, labels)\n",
    "nn_models['NN_smote'] = nn_model_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a05e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_ov.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nn_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(norm_test_set.values, (len(norm_test_set), 1, len(norm_test_set.columns)))\n",
    "test_pred = (nn_model_ov.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378de181",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_label,test_pred)\n",
    "#il parametro fmt serve per evitare la notazione esponenziale dei numeri\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred, 'Neural Network', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fb338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_curve_plot(nn_model_ov, norm_test_set, test_label, test_pred, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b19345e",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c4d02",
   "metadata": {},
   "source": [
    "Let's test the KNN on oversampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4dea5",
   "metadata": {},
   "source": [
    "For the KNN we need to remove the categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36019fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_ov_train_set = training.drop(columns=['sex_num', 'hand_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbfde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_metrics = ['euclidean', 'manhattan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_weights = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_algorithms = ['ball_tree', 'kd_tree', 'brute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c511720",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': k_range,\n",
    "    'metric': knn_metrics,\n",
    "    'algorithm': knn_algorithms,\n",
    "    'weights': knn_weights\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f51ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=10, scoring='accuracy')\n",
    "knn_grid.fit(knn_ov_train_set, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e897700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(knn_grid.best_score_))\n",
    "print('Parameters: ' + str(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**knn_grid.best_params_).fit(knn_ov_train_set, labels)\n",
    "knn_models['knn_ov'] = knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1849d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred = knn.predict(knn_ov_train_set)\n",
    "report_scores(labels,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f147e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_pred = knn.predict(knn_test_set)\n",
    "report_scores(test_label,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a31944",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(knn_test_set, test_label, test_pred, 'KNN','nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53133b4",
   "metadata": {},
   "source": [
    "Train KNN model with normalized oversample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=10, scoring='accuracy')\n",
    "norm_knn_train_set = normalize_dataset(knn_ov_train_set)\n",
    "norm_knn_test_set = normalize_dataset(knn_test_set)\n",
    "knn_grid.fit(norm_knn_train_set, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(knn_grid.best_score_))\n",
    "print('Parameters: ' + str(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**knn_grid.best_params_).fit(norm_knn_train_set, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b5f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred = knn.predict(norm_knn_train_set)\n",
    "report_scores(labels,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861a297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = knn.predict(norm_knn_test_set)\n",
    "report_scores(test_label,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e633b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882dfb60",
   "metadata": {},
   "source": [
    "# Sumup Classifiers Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c6bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifiers.update(dt_models)\n",
    "classifiers.update(svm_models)\n",
    "classifiers.update(rb_models)\n",
    "classifiers.update(gnb_models)\n",
    "classifiers.update(knn_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbbb8ee",
   "metadata": {},
   "source": [
    "In this section, the performances of all the analyzed classifiers are compared on the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc87f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_roc_curves(classifiers, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2297ce",
   "metadata": {},
   "source": [
    "### Decision tree versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b1e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_models(dt_models, 'Decision Tree', test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b69e32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TRAINING SCORES')\n",
    "compare_scores(dt_models,train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8dd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TEST SCORES')\n",
    "compare_scores(dt_models,test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c35fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_roc_curves(dt_models,test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb38b9",
   "metadata": {},
   "source": [
    "### SVM versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(svm_models, 'SVM', test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cbfc8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TRAINING SCORES')\n",
    "compare_scores(svm_models,train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TEST SCORES')\n",
    "compare_scores(svm_models,test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797feb2",
   "metadata": {},
   "source": [
    "### Rule based versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(rb_models, 'Rule Based', test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda9528",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TRAINING SCORES')\n",
    "compare_scores(rb_models,train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TEST SCORES')\n",
    "compare_scores(rb_models,test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb156cf",
   "metadata": {},
   "source": [
    "### Gaussain Naive Bayes versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dddabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(gnb_models, 'Gaussain Naive Bayes', test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753ea57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TRAINING SCORES')\n",
    "compare_scores(gnb_models,train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TEST SCORES')\n",
    "compare_scores(gnb_models,test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bcfc2",
   "metadata": {},
   "source": [
    "### Neural Network versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_nn_models(models_list, classifier_name, test_set, test_label):\n",
    "    i = 0\n",
    "    col_count = len(train_set.columns)\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=len(models_list), figsize=(18,6), sharey=True)\n",
    "    title = classifier_name + ' | Confusion Matrix comparison'\n",
    "    plt.suptitle(title)\n",
    "    for model in models_list.keys():\n",
    "        x_test = np.reshape(test_set.values, (len(test_set), 1, col_count))\n",
    "        test_pred = (models_list[model].predict(x_test) > 0.5).astype(\"int32\")\n",
    "        cm=confusion_matrix(test_label,test_pred)\n",
    "        sns.heatmap(cm, ax=axs[i], annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "        axs[i].set_title(model)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_nn_models(nn_models, 'Neural Network',norm_test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07257c",
   "metadata": {},
   "source": [
    "### KNN versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5beebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(knn_models, 'k-Nearest Neighbors', knn_test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcaa75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TRAINING SCORES')\n",
    "compare_scores(knn_models,knn_train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f378a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\t TEST SCORES')\n",
    "compare_scores(knn_models,knn_test_set, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
