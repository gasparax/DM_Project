{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b0fe57",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beddf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pydotplus \n",
    "import statistics \n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import Image  \n",
    "import scikitplot as skplt\n",
    "import wittgenstein as lw\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.spatial.distance import pdist,  squareform\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, classification_report, confusion_matrix, plot_confusion_matrix # For Model evaluation\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574186fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load of the data\n",
    "DATASET_DIR = \"dataset\" + os.path.sep\n",
    "#index_col=False say to not use the first column as ID\n",
    "df_players = pd.read_csv('players.csv', sep=',', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf110a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0220572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players[['sex', 'hand', 'best_rank','best_rank_points', 'best_of_3_match', 'best_of_5_match',\n",
    "           'best_of_3_wins', 'best_of_5_wins', 'w_finals', 'tot_minutes', 'sv1st', 'sv1st_win', 'sv2nd_win', \n",
    "           'df', 'ace_perc', 'bpS_perc', 'wmatch', 'lmatch', 'nmatch', 'n_tourney']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data(dataset, variables): #mapping categorical into numerical\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19034b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df_players[['sex', 'hand', 'best_rank','best_rank_points', 'best_of_3_match', 'best_of_5_match',\n",
    "           'best_of_3_wins', 'best_of_5_wins', 'w_finals', 'tot_minutes', 'sv1st', 'sv1st_win', 'sv2nd_win', \n",
    "           'df', 'ace_perc', 'bpS_perc', 'wmatch', 'lmatch', 'nmatch', 'n_tourney']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'hand']\n",
    "df_p = discretize_data(df_p, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5453a06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_p.drop(columns=['sex', 'hand'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15556d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "df_p.loc[((df_p['best_rank']>0) & (df_p['best_rank']<=threshold)), 'ranked'] = 'high'\n",
    "df_p.loc[((df_p['best_rank']>0) & (df_p['best_rank']>threshold)), 'ranked'] = 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2351e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif = df_p[df_p['best_rank']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif.drop(columns=['best_rank'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d763d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df_classif.pop('ranked')\n",
    "train_set, test_set, train_label, test_label = train_test_split(df_classif, label, stratify =label, test_size=0.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e27f5c",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, \n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=list(train_set.columns),  \n",
    "                         class_names=['high', 'low'],  \n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77f38b",
   "metadata": {},
   "source": [
    "#### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.predict_proba(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate the accuracy on the train set and the test set\n",
    "#metrics also contains precision, recall, f1 and the support\n",
    "print('Accuracy train set ', metrics.accuracy_score(train_label, train_pred_dt))\n",
    "print('Accuracy test set ', metrics.accuracy_score(test_label, test_pred_dt))\n",
    "print('Precision train set ', metrics.precision_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('Recall train set ', metrics.recall_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('F1 score train set ', metrics.f1_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('Support train set ', metrics.precision_recall_fscore_support(train_label, train_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6406994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics computed on the test set\n",
    "def report_scores(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['low', 'high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per il training set\n",
    "report_scores(train_label, train_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f763cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per il test set\n",
    "report_scores(test_label, test_pred_dt)\n",
    "#l'accuracy è un buon indicatore, è significativa se è maggiore dell'accuracy della majority class. in caso di \n",
    "#situazione unbalance anche la precision e la recall aiutano a capire quanti errori abbiamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(dt, train_set, train_label, cv=3, return_train_score= True)\n",
    "print('Fit time ', statistics.mean(scores['fit_time']))\n",
    "print('Score time ', statistics.mean(scores['score_time']))\n",
    "print('Test score ', statistics.mean(scores['test_score']))\n",
    "print('Train score ', statistics.mean(scores['train_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3022571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute confusion matrix\n",
    "cm = confusion_matrix(test_label, test_pred_dt)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb87971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is possible to plot the confusion matrix \n",
    "plot_confusion_matrix(dt, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3251e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true labels - different colors for different class\n",
    "color = ['red' if label=='low'  else 'green' for label in test_label]\n",
    "plt.scatter(test_set.iloc[:, 5].values, test_set.iloc[:, 2].values , c=color, s=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625a0e5",
   "metadata": {},
   "source": [
    "#### excluded raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_rank = df_p[df_p['best_rank']==0]\n",
    "df_to_rank.drop(columns=['best_rank'], inplace=True, axis=1)\n",
    "df_to_rank.drop(columns = ['ranked'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_pred_dt = dt.predict(df_to_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd101035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_rank['ranked'] = unknown_pred_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37603b50",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a719ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='sigmoid', C=0.5, gamma='scale', probability=True)\n",
    "svm.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on the test test\n",
    "test_pred_proba_svm = svm.predict_proba(test_set)\n",
    "test_pred_proba_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svm = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c848b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the performance of the model\n",
    "print(classification_report(test_label, \n",
    "                            test_pred_svm, \n",
    "                            target_names=['low', 'high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca56382",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_proba = svm.predict_proba(test_set)\n",
    "skplt.metrics.plot_roc_curve(test_label.values, test_pred_proba) #roc curve for only one model\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d91cb",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7754312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif = df_p[df_p['best_rank']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif.drop(columns=['ranked'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif.loc[((df_classif['best_rank']>0) & (df_classif['best_rank']<=threshold)), 'ranked'] = True #low\n",
    "df_classif.loc[((df_classif['best_rank']>0) & (df_classif['best_rank']>threshold)), 'ranked'] = False #high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif.drop(columns=['best_rank'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76894fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df_classif.pop('ranked')\n",
    "train_set, test_set, train_label, test_label = train_test_split(df_classif, label, stratify =label, test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)\n",
    "grid_search.fit(train_set, train_label, pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters setting ', grid_search.cv_results_['params'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcffc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and fit the rule-based model\n",
    "#this function requires only one dataset with the labels. \n",
    "#To do so, we concatenate the train_set and the train_label\n",
    "ripper = lw.RIPPER(k=1, prune_size=0.50)\n",
    "datas = pd.concat([train_set, train_label], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca345c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd992e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7469cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with rule based classifiers it is possible to extract the reasons for the prediction.\n",
    "#only for the positive predictions\n",
    "ripper.predict(test_set[:15], give_reasons=True) #give_reasons dice quali regole sono vere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e3011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d6c5dae",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33a475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "743afd43",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db210337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d8dc76",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80706c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9938e790",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0e8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0d356a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808ae76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72b6c001",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552f2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e283e7",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaab9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
