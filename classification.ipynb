{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daab5335",
   "metadata": {},
   "source": [
    "<b>Data mining Project - 2021/22</b><br/>\n",
    "<span>\n",
    "<b>Authors:</b> Mariagiovanna Rotundo (560765), Nunzio Lopardo (600005)</a> and Renato Eschini (203021)<br/>\n",
    "<b>Group:</b>3<br/>\n",
    "<b>Release date:</b> 26/12/2021\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0fe57",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cfe40a",
   "metadata": {},
   "source": [
    "In this notebook we use different classificators for the classification task and we evaluate the performaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea563e",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beddf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pydotplus \n",
    "import statistics \n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import Image  \n",
    "import scikitplot as skplt\n",
    "import wittgenstein as lw\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.spatial.distance import pdist,  squareform\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, classification_report, plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay # For Model evaluation\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008b8d5",
   "metadata": {},
   "source": [
    "**Loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574186fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load of the data\n",
    "DATASET_DIR = \"dataset\" + os.path.sep\n",
    "#index_col=False say to not use the first column as ID\n",
    "df_players = pd.read_csv('players.csv', sep=',', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf110a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_players.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad539d",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201f798",
   "metadata": {},
   "source": [
    "In this section are defined the functions used in the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fae0f",
   "metadata": {},
   "source": [
    "**function to discretize categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data(dataset, variables): #mapping categorical into numerical\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d96c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics computed on the test set\n",
    "def report_scores(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['low', 'high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea869650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_errors(test_label, test_pred):\n",
    "    spotted_errors = []\n",
    "    for i in range(len(test_label)):\n",
    "        if(test_label.array[i]!= test_pred[i]):\n",
    "            spotted_errors.append('darkred')\n",
    "        else:\n",
    "            spotted_errors.append('darkgray')\n",
    "    return spotted_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e6d95",
   "metadata": {},
   "source": [
    "**Plot the neural network training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df32bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nn_training_history(history):\n",
    "    from matplotlib.pyplot import figure\n",
    "    fig, (acc_plot, loss_plot) = plt.subplots(2, figsize=(15, 6), dpi=240)\n",
    "    fig.suptitle('Accuracy and Loss trends')\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    acc_plot.plot(epochs, acc, label='Training Acc')\n",
    "    acc_plot.plot(epochs, val_acc, label='Validation Acc')\n",
    "    acc_plot.legend(loc='best')\n",
    "    acc_plot.set_ylabel('Accuracy')\n",
    "    acc_plot.set_ylim([0,1])\n",
    "    acc_plot.grid(True)\n",
    "    loss_plot.plot(epochs, loss, label='Trining Loss')\n",
    "    loss_plot.plot(epochs, val_loss, label='Validation Loss')\n",
    "    loss_plot.legend(loc='best')\n",
    "    loss_plot.set_ylabel('Loss')\n",
    "    loss_plot.set_ylim([0,1])\n",
    "    loss_plot.set_xlabel('Epochs')\n",
    "    loss_plot.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a640d8",
   "metadata": {},
   "source": [
    "**Scatter plot comparison real/classified/misclassified data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_pred_data(test_set, test_label, test_pred, classifier_name, x, y):\n",
    "    fig, (test_true_plt, test_pred_plt, errors_plt) = plt.subplots(1,3, figsize=(18,6), sharey=True)\n",
    "    title = classifier_name + ' | Real vs Predicted labels'\n",
    "    plt.suptitle(title)\n",
    "    test_true_plt.set_title('True Label')\n",
    "    test_true_plt.scatter(test_set[x].values, test_set[y].values, c=test_label.values, s=25, cmap='viridis')\n",
    "    test_pred_plt.set_title('Predicted Label')\n",
    "    test_pred_plt.scatter(test_set[x].values, test_set[y].values, c=test_pred, s=25, cmap='viridis')\n",
    "    spotted_errors = spot_errors(test_label, test_pred)\n",
    "    errors_plt.set_title('Misclassification')\n",
    "    errors_plt.scatter(test_set[x].values, test_set[y].values, c=spotted_errors, s=25, cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb5fbe",
   "metadata": {},
   "source": [
    "**Print the dataset composition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_composition(train_set, train_labels, test_set, test_labels):\n",
    "    print(f\"{len(train_labels)} training samples:\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 0])} samples for the class Low Rank\")\n",
    "    print(f\"\\t- {len(train_labels[train_labels == 1])} samples for the class High Rank\")\n",
    "    print(f\"\\n{len(test_labels)} test samples:\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 0])} samples for the class Low Rank\")\n",
    "    print(f\"\\t- {len(test_labels[test_labels == 1])} samples for the class High Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24056fdd",
   "metadata": {},
   "source": [
    "**Plot the ROC curve and compute the AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(model, test_set, test_label, test_pred, classifier_name):\n",
    "    x_test = np.reshape(test_set.values, (len(test_set), 1, len(test_set.columns)))\n",
    "    y_pred_keras = model.predict(x_test).ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(test_label, test_pred)\n",
    "    auc_area = auc(fpr, tpr)\n",
    "    label_name = classifier_name + '(area = {:.3f})'.format(auc_area)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label=label_name)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365ed9a",
   "metadata": {},
   "source": [
    "**Plot confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_mx(test_label, test_pred):\n",
    "    cm = confusion_matrix(test_label, test_pred, labels=test_label.unique())\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= ['low', 'high'])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab265d",
   "metadata": {},
   "source": [
    "**Plot multiple confusion matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b72def",
   "metadata": {},
   "source": [
    "Given a dictionary of trained classifiers ({classifier_name: model}) plots the confusion matrix for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models_list, classifier_name, test_set, test_label):\n",
    "    i = 0\n",
    "    col_count = len(train_set.columns)\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=len(models_list), figsize=(18,6), sharey=True)\n",
    "    title = classifier_name + ' | Confusion Matrix comparison'\n",
    "    plt.suptitle(title)\n",
    "    for model in models_list.keys():\n",
    "        test_pred =  models_list[model].predict(test_set)\n",
    "        cm=confusion_matrix(test_label,test_pred)\n",
    "        sns.heatmap(cm, ax=axs[i], annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "        axs[i].set_title(model)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600fca10",
   "metadata": {},
   "source": [
    "**Function to normalize a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(df):\n",
    "    cols_to_norm = ['best_rank_points', 'w_tourney', 'tot_minutes', 'sv1st', 'sv1st_win', 'sv2nd_win', \n",
    "           'df', 'ace', 'bpS', 'wmatch', 'lmatch', 'nmatch', 'n_tourney']\n",
    "    df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc8d25",
   "metadata": {},
   "source": [
    "## Data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19034b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_players[['sex', 'hand','best_rank','best_rank_points', 'w_tourney', 'tot_minutes', 'sv1st', 'sv1st_win', 'sv2nd_win', \n",
    "           'df', 'ace', 'bpS', 'wmatch', 'lmatch', 'nmatch', 'n_tourney']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee63aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_match = 1\n",
    "\n",
    "# df_filtered = df_players[\n",
    "#     (df_players['best_rank']>0) & \n",
    "#     (df_players['best_rank_points']>=0) & \n",
    "#     (df_players['tot_minutes']>0) & \n",
    "#     (df_players['ace']>=0) & \n",
    "#     (df_players['bpS']>=0)][[\n",
    "# 'best_rank', \n",
    "# 'best_rank_points',                            \n",
    "# 'tot_minutes',\n",
    "# 'sv1st',\n",
    "# 'sv1st_win', \n",
    "# 'sv2nd_win', \n",
    "# 'df', \n",
    "# 'ace', \n",
    "# 'bpS', \n",
    "# 'nmatch',\n",
    "# 'wmatch',\n",
    "# 'lmatch',\n",
    "# 'n_tourney',\n",
    "# 'w_tourney']]\n",
    "# df_filtered = df_filtered.loc[df_filtered['nmatch'] > n_match]\n",
    "\n",
    "# df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'hand']\n",
    "df_filtered = discretize_data(df_filtered, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5453a06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(columns=['sex', 'hand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7c741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15556d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']<=threshold)), 'ranked'] = 1 #high\n",
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']>threshold)), 'ranked'] = 0 #low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']<=threshold))].shape[0] #number of high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fe19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.loc[((df_filtered['best_rank']>0) & (df_filtered['best_rank']>threshold))].shape[0] #number of low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2351e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = df_filtered[df_filtered['best_rank']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = df_classification.drop(columns=['best_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1148d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d763d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df_classification.pop('ranked')\n",
    "train_set, test_set, train_label, test_label = train_test_split(df_classification, label, stratify = label, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f817f1c",
   "metadata": {},
   "source": [
    "**Dataset normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_set = normalize_dataset(train_set)\n",
    "norm_test_set = normalize_dataset(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12d47e",
   "metadata": {},
   "source": [
    "**Dataset composition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d83c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dataset_composition(train_set, train_label, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c54f96",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e27f5c",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, \n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=list(train_set.columns),  \n",
    "                         class_names=['low', 'high'],  #[0, 1]\n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77f38b",
   "metadata": {},
   "source": [
    "#### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.predict_proba(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate the accuracy on the train set and the test set\n",
    "#metrics also contains precision, recall, f1 and the support\n",
    "print('Accuracy train set ', metrics.accuracy_score(train_label, train_pred_dt))\n",
    "print('Accuracy test set ', metrics.accuracy_score(test_label, test_pred_dt))\n",
    "print('Precision train set ', metrics.precision_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('Recall train set ', metrics.recall_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('F1 score train set ', metrics.f1_score(train_label, train_pred_dt, average='weighted'))\n",
    "print('Support train set ', metrics.precision_recall_fscore_support(train_label, train_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per il training set\n",
    "report_scores(train_label, train_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f763cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per il test set\n",
    "report_scores(test_label, test_pred_dt)\n",
    "#l'accuracy è un buon indicatore, è significativa se è maggiore dell'accuracy della majority class. in caso di \n",
    "#situazione unbalance anche la precision e la recall aiutano a capire quanti errori abbiamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(dt, train_set, train_label, cv=3, return_train_score= True)\n",
    "print('Fit time ', statistics.mean(scores['fit_time']))\n",
    "print('Score time ', statistics.mean(scores['score_time']))\n",
    "print('Test score ', statistics.mean(scores['test_score']))\n",
    "print('Train score ', statistics.mean(scores['train_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3022571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute confusion matrix\n",
    "cm = confusion_matrix(test_label, test_pred_dt)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb87971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is possible to plot the confusion matrix \n",
    "plot_confusion_matrix(dt, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80934944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_result = test_set\n",
    "#test_result['ranked'] = test_label\n",
    "#print classification for pairs of attributes/columns\n",
    "#sns.pairplot(data = test_result, hue = 'ranked', palette = \"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3251e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true labels - different colors for different class\n",
    "plt.scatter(test_set['best_rank_points'].values, test_set['sv1st'].values , c=test_label, s=20);\n",
    "plt.show()\n",
    "plt.scatter(test_set['nmatch'].values, test_set['sv1st'].values , c=test_label, s=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37603b50",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a719ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='sigmoid', C=0.5, gamma='scale', probability=True)\n",
    "svm.fit(train_set, train_label)\n",
    "svm_models['svm_original'] = svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cba226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_svm = svm.predict(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on the test test\n",
    "test_pred_proba_svm = svm.predict_proba(test_set)\n",
    "test_pred_proba_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svm = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c848b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the performance of the model\n",
    "report_scores(test_label, test_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d91cb",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6247b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)\n",
    "grid_search.fit(train_set, train_label, pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters setting ', grid_search.cv_results_['params'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcffc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and fit the rule-based model\n",
    "#this function requires only one dataset with the labels. \n",
    "#To do so, we concatenate the train_set and the train_label\n",
    "ripper = lw.RIPPER(k=1, prune_size=0.50)\n",
    "datas = pd.concat([train_set, train_label], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018587d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models['rb_original'] = ripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_train = ripper.predict(train_set)\n",
    "report_scores(train_label, ripper_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred = ripper.predict(test_set)\n",
    "report_scores(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd992e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8036ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ripper, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_reasons = ripper.predict(test_set, give_reasons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02de896",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [i for i,elem in enumerate(ripper_pred_reasons[0]) if elem == True]\n",
    "rules_used = [ripper_pred_reasons[1][elem] for i,elem in enumerate(indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c5dae",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87cd458",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2211801",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3443c11",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c946e",
   "metadata": {},
   "source": [
    "**Train the Gaussain Naive Bayes classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a98ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model.fit(train_set, train_label)\n",
    "gnb_models['GNB_original'] = gnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5de5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = gnb_model.predict(test_set)\n",
    "print(classification_report(test_label, test_pred, target_names = ['low','high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312ff3c",
   "metadata": {},
   "source": [
    "The performance report reveals the low capacity of the GNB classifier to correctly classify the hig rank players. This is due to the highly imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bd7f1",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6796d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_label, test_pred, labels=gnb_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= ['high', 'low'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938e790",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_set.values, test_set.values, train_label.values, test_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DecisionTreeClassifier (default) as Base Learners\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "X_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6df772",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb045285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support Vector Classifier as Base Learners\n",
    "svc=SVC(probability=True, kernel='linear')\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc =AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "X_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c22328f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9e09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68402e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0d356a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(train_set,train_label)\n",
    "y_pred=clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99b60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for train dataset\n",
    "X_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ddd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904056ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72b6c001",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f2473",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c820c",
   "metadata": {},
   "source": [
    "In the following list we will save all the trained Neural Network models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4245c8f",
   "metadata": {},
   "source": [
    "Define and compile the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn_model(optimizer = 'adam', activation='relu', dropout_rate=0.2, neurons=20, loss='binary_crossentropy'): #specify parameters so that we can do grid search\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(1, len(train_set.columns))),\n",
    "        tf.keras.layers.Dense(neurons, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(neurons, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),    \n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(model, train_set, train_label, epochs=60, batch_size=256,validation_split=0.2, verbose=False, class_wieghts=None):\n",
    "    x_train = np.reshape(train_set.values, (len(train_set), 1, len(train_set.columns)))\n",
    "    if class_weights:\n",
    "        history = model.fit(x_train, train_label,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=validation_split,\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=verbose)\n",
    "    else:\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=validation_split,\n",
    "                            verbose=verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = base_nn_model()\n",
    "nn_model, history = train_nn_model(nn_model, norm_train_set, train_label)\n",
    "nn_models['NN_original'] = nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109a915",
   "metadata": {},
   "source": [
    "Train the model using the original and normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40175bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34c0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_nn_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858aced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.reshape(norm_train_set.values, (len(norm_train_set), 1, len(train_set.columns)))\n",
    "train_pred = (nn_model.predict(x_train_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f79a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(norm_test_set.values, (len(norm_test_set), 1, col_count))\n",
    "test_pred = (nn_model.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaea37e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a27b8",
   "metadata": {},
   "source": [
    "Given the trained NN model, let's look the cofusion matrix on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb899c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_label,test_pred)\n",
    "#il parametro fmt serve per evitare la notazione esponenziale dei numeri\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54943c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_pred_data(norm_test_set, norm_test_label, test_pred, 'Neural Network', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560548a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_curve_plot(nn_model, norm_test_set, norm_test_label, test_pred, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e283e7",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaab9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94458049",
   "metadata": {},
   "source": [
    "Fit and scoring the classifier using the function *GridSearchCV*, by sklearn, that automatically compute the best combination of parameters for the model training. Below are created the set of parameters for the KNN training that the function will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14025c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_metrics = ['euclidean', 'manhattan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9da18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_weights = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_algorithms = ['ball_tree', 'kd_tree', 'brute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5747837",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': k_range,\n",
    "    'metric': knn_metrics,\n",
    "    'algorithm': knn_algorithms,\n",
    "    'weights': knn_weights\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=10, scoring='accuracy')\n",
    "knn_grid.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b46c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(knn_grid.best_score_))\n",
    "print('Parameters: ' + str(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec614fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**knn_grid.best_params_).fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f431e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_knn = knn.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label,test_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred_knn, 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3e101",
   "metadata": {},
   "source": [
    "As we know from the theory, the nearest neighbor classifiers can be biased by noise points that have oversized data values that can miss lead the classification task. The solution to this problem is normalization, in the following lines of code a normalized dataset is created using the *MinMaxScaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cs_norm_minmax = minmax_scaler.fit_transform(df_classification.values)\n",
    "norm_train_set, norm_test_set, norm_train_label, norm_test_label = train_test_split(cs_norm_minmax, label, stratify=label, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7843b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=10, scoring='accuracy')\n",
    "knn_grid.fit(norm_train_set, norm_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(knn_grid.best_score_))\n",
    "print('Parameters: ' + str(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**knn_grid.best_params_).fit(norm_train_set, norm_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_knn = knn.predict(norm_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a59e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(test_label,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fe86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18aff1c",
   "metadata": {},
   "source": [
    "# Classification with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set weights\n",
    "weights = {0:1.0, 1:100.0} #0=low, 1 = high\n",
    "balance = [{0:1,1:100}, {0:1,1:50}, {0:1,1:10}, {0:1,1:1}, 'balanced']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1967c",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, class_weight=weights,\n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cca9c",
   "metadata": {},
   "source": [
    "#### choise of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "param_grid = dict(class_weight=balance)\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, class_weight={0: 1, 1: 50},\n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cce696",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=list(train_set.columns),  \n",
    "                         class_names=['low', 'high'],  #[0, 1]\n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315440a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aede62",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021165ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dt, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394cf5e",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f646f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='scale', class_weight=weights)\n",
    "svm.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(train_set)\n",
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da100266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the performance of the model\n",
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874950fe",
   "metadata": {},
   "source": [
    "#### choise of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "param_grid = dict(class_weight=balance)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c39139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='scale', class_weight={0: 1, 1: 10})\n",
    "svm.fit(train_set, train_label)\n",
    "svm_models['svm_weighted'] = svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svm.predict(test_set)\n",
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(train_set)\n",
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308de8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d810dc5",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79794ecc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5], \"class_weight\": balance}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)\n",
    "grid_search.fit(train_set, train_label, pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bcec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters setting ', grid_search.cv_results_['params'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper = lw.RIPPER(k=1, prune_size=0.50)\n",
    "datas = pd.concat([train_set, train_label], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1, class_weight = {0: 1, 1: 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bed9e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models['rb_weighted'] = ripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_train = ripper.predict(train_set)\n",
    "report_scores(train_label, ripper_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred = ripper.predict(test_set)\n",
    "report_scores(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c145dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea670e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ripper, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_reasons = ripper.predict(test_set, give_reasons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94719e8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indexes = [i for i,elem in enumerate(ripper_pred_reasons[0]) if elem == True]\n",
    "rules_used = [ripper_pred_reasons[1][elem] for i,elem in enumerate(indexes)]\n",
    "rules_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36841f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5c3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba5f2afb",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca905dc2",
   "metadata": {},
   "source": [
    "Now let's re-run the neural network classifier using the weighted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45de42",
   "metadata": {},
   "source": [
    "#### choise of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ca7d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights_nn = {0: 0.75, 1: 2.8}\n",
    "class_weights = class_weight.compute_class_weight(class_weight = weights_nn,\n",
    "                                                 classes = np.unique(train_label),\n",
    "                                                 y = train_label)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1150bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_w = base_nn_model()\n",
    "nn_model_w, history = train_nn_model(nn_model_w, norm_train_set, train_label)\n",
    "nn_models['NN_weighted'] = nn_model_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65bcdc",
   "metadata": {},
   "source": [
    "Train the model using the original and normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939426e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_nn_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.reshape(norm_train_set.values, (len(norm_train_set), 1, len(norm_train_set.columns)))\n",
    "train_pred = (nn_model_w.predict(x_train_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3084b42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63395daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(norm_test_set.values, (len(norm_test_set), 1, col_count))\n",
    "test_pred = (nn_model_w.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ad27f",
   "metadata": {},
   "source": [
    "Given the trained NN model, let's look the cofusion matrix on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171671fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_label,test_pred)\n",
    "#il parametro fmt serve per evitare la notazione esponenziale dei numeri\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e421231",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_pred_data(norm_test_set, test_label, test_pred, 'Neural Network', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1c991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_curve_plot(nn_model_w, norm_test_set, test_label, test_pred, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18890b7c",
   "metadata": {},
   "source": [
    "# Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(sampling_strategy=0.3)\n",
    "training, labels = oversample.fit_resample(train_set, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256f550",
   "metadata": {},
   "source": [
    "**Original Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562df2b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dataset_composition(train_set, train_label, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d91e6",
   "metadata": {},
   "source": [
    "**Dataset after oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c65488",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataset_composition(training, labels, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed2ace",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2505a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                  max_depth=5, \n",
    "                                  min_samples_split=3, min_samples_leaf=4)\n",
    "dt = dt.fit(training, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = dt.predict(train_set)\n",
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fb11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_dt = dt.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cbfa6",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='sigmoid', gamma='scale')\n",
    "svm.fit(training, labels)\n",
    "svm_models['svm_ov'] = svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a16b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(train_set)\n",
    "report_scores(train_label, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dca09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7bc12",
   "metadata": {},
   "source": [
    "### Rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we run a grid search to find the best configuration of parameters' values\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid)\n",
    "grid_search.fit(training, labels, pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters setting ', grid_search.cv_results_['params'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper = lw.RIPPER(k=1, prune_size=0.50)\n",
    "datas = pd.concat([training, labels], axis=1)\n",
    "ripper.fit(datas, class_feat='ranked', pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb151edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case the model is a set of rules\n",
    "ripper.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_models['rb_ov'] = ripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8adf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred_train = ripper.predict(train_set)\n",
    "report_scores(train_label, ripper_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3557a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_pred = ripper.predict(test_set)\n",
    "report_scores(test_label, ripper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the performance of the classifier\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994be595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_mx(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99600b5f",
   "metadata": {},
   "source": [
    "### Gaussain Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf880a7",
   "metadata": {},
   "source": [
    "Gaussain Naive Bayes using the oversampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c35c7",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea85870",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950dc6ac",
   "metadata": {},
   "source": [
    "**Train the Gaussain Naive Bayes classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model.fit(training, labels)\n",
    "gnb_models['GNB_ov'] = gnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f978a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = gnb_model.predict(test_set)\n",
    "print(classification_report(test_label, test_pred, target_names = ['low','high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b1ddc",
   "metadata": {},
   "source": [
    "The performance report reveals the low capacity of the GNB classifier to correctly classify the hig rank players. This is due to the highly imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f1fea",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c84900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ripper, test_set, test_label)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b69168",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2620a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ov_train_set = normalize_dataset(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_ov = base_nn_model()\n",
    "nn_model_ov, history = train_nn_model(nn_model_ov, norm_ov_train_set, labels)\n",
    "nn_models['NN_smote'] = nn_model_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a05e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_ov.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nn_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(norm_test_set.values, (len(norm_test_set), 1, col_count))\n",
    "test_pred = (nn_model_ov.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378de181",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(test_label,test_pred)\n",
    "#il parametro fmt serve per evitare la notazione esponenziale dei numeri\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_pred_data(test_set, test_label, test_pred, 'Neural Network', 'nmatch', 'best_rank_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fb338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_curve_plot(nn_model_ov, norm_test_set, norm_test_label, test_pred, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882dfb60",
   "metadata": {},
   "source": [
    "# Classifiers Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3884081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d877690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4bcfc2",
   "metadata": {},
   "source": [
    "## Neural Network versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6ee9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fde526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_nn_models(models_list, classifier_name, test_set, test_label):\n",
    "    i = 0\n",
    "    col_count = len(train_set.columns)\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=len(models_list), figsize=(18,6), sharey=True)\n",
    "    title = classifier_name + ' | Confusion Matrix comparison'\n",
    "    plt.suptitle(title)\n",
    "    for model in models_list.keys():\n",
    "        x_test = np.reshape(test_set.values, (len(test_set), 1, col_count))\n",
    "        test_pred = (models_list[model].predict(x_test) > 0.5).astype(\"int32\")\n",
    "        cm=confusion_matrix(test_label,test_pred)\n",
    "        sns.heatmap(cm, ax=axs[i], annot=True,cmap=plt.cm.Blues, fmt='g')\n",
    "        axs[i].set_title(model)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_nn_models(nn_models, 'Neural Network',norm_test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dddabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(gnb_models, 'Gaussain Naive Bayes', test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369b7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2777b22f",
   "metadata": {},
   "source": [
    "### SVM versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(svm_models, 'SVM', test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893a642",
   "metadata": {},
   "source": [
    "### Rule based versions comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf457004",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(rb_models, 'Rule based', test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db26832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fa1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
