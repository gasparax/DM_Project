{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a59b58",
   "metadata": {},
   "source": [
    "<b>Data mining Project - 2021/22</b><br/>\n",
    "<span>\n",
    "<b>Authors:</b> Mariagiovanna Rotundo (560765), Nunzio Lopardo (600005)</a> and Renato Eschini (203021)<br/>\n",
    "<b>Group:</b>3<br/>\n",
    "<b>Release date:</b> 26/12/2021\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04b76a",
   "metadata": {},
   "source": [
    "# Task 2: Data Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7bede9",
   "metadata": {},
   "source": [
    "This workbook contains a clustering analysis on the tennis dataset.\n",
    "This dataset was derived from the \"tennis_matches.csv\" dataset by deriving player information from the matches played.\n",
    "\n",
    "A new \"performance\" dataset was also derived in which the data was reprocessed to use only essential and important information for a player-related clustering analysis, eg. only players who have played more than a certain number of games will be considered, only numerical attributes, percentages strictly greater than zero, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd3531",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import date\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pyclustering.cluster.xmeans import xmeans\n",
    "from pyclustering.cluster.birch import birch\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster import cluster_visualizer, cluster_visualizer_multidim\n",
    "import seaborn as sns\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42114975",
   "metadata": {},
   "source": [
    "**Loading the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05a722",
   "metadata": {},
   "source": [
    "Load \"players.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ef4a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load of the data\n",
    "DATASET_DIR = \"dataset\" + os.path.sep\n",
    "#index_col=False say to not use the first column as ID\n",
    "df_players = pd.read_csv('players.csv', sep=',', index_col=0) \n",
    "df_players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0764821",
   "metadata": {},
   "source": [
    "Print info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e67c0",
   "metadata": {},
   "source": [
    "## Perfomances dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08db675",
   "metadata": {},
   "source": [
    "We analyze the distribution of players by number of matches played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d964765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df_players['nmatch'], bins=\"auto\", binrange=(10,400), color=\"lightgreen\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d080046",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_players['best_rank'], bins=\"auto\", binrange=(10,400), color=\"lightgreen\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df3708c",
   "metadata": {},
   "source": [
    "We create the performance dataset by taking only some attributes and the players who have at least a fixed number of n_match games (for example at least 300 games played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea0a17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_match = 100\n",
    "\n",
    "df_performances_org = df_players[\n",
    "    (df_players['best_rank']>0) & \n",
    "    (df_players['best_rank_points']>=0) & \n",
    "    (df_players['tot_minutes']>0) & \n",
    "    (df_players['ace_perc']>=0) & \n",
    "    (df_players['bpS_perc']>=0)][[\n",
    "'best_rank', \n",
    "'best_rank_points',                            \n",
    "'tot_minutes',\n",
    "'sv1st_win', \n",
    "'sv2nd_win', \n",
    "'df', \n",
    "'ace_perc', \n",
    "'bpS_perc', \n",
    "'nmatch', \n",
    "'best_of_3_match', \n",
    "'best_of_3_wins', \n",
    "'best_of_5_match', \n",
    "'best_of_5_wins', \n",
    "'n_tourney']]\n",
    "df_performances = df_performances_org.loc[df_performances_org['nmatch'] > n_match]\n",
    "\n",
    "df_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02b054",
   "metadata": {},
   "source": [
    "## Elimination of highly correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f999b",
   "metadata": {},
   "source": [
    "We begin by examining the correlations between the attributes of the dataset to be clustered in order to identify the highly correlated couples. Dropping redundant attributes benefits the analysis by reducing the dimensionality of the dataset and rising the influence that more useful feature could have on the whole clustering process.\n",
    "\n",
    "With such aim in mind, we fix a maximum threshold value in order to identify highly correlated features and subsequently drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bd4e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "sns.heatmap( df_performances.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f7b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_threshold = 0.9\n",
    "print(\"Att. A\\t\\t\\tAtt. B\\t\\t\\tCorr(A,B)\")\n",
    "for i in range(0, len(df_performances.columns)):\n",
    "    for j in range(i+1, len(df_performances.columns)):\n",
    "        corr = df_performances[df_performances.columns[i]].corr(df_performances[df_performances.columns[j]])\n",
    "        if  corr > corr_threshold:\n",
    "            print(df_performances.columns[i] + \"\\t\\t\\t\" + df_performances.columns[j] + \"\\t\\t\\t\" + '{:.4f}'.format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc22d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#   \n",
    "corr_columns = ['best_of_3_match', 'best_of_5_match', 'sv2nd_win', 'tot_minutes']\n",
    "a = df_performances.drop(corr_columns, axis=1, inplace=False)\n",
    "df_performances = a\n",
    "df_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc785048",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(1,16))\n",
    "\n",
    "visualizer.fit(df_performances)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1338f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4840190",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_list = list()\n",
    "sil_list = list()\n",
    "\n",
    "max_k = 15\n",
    "for k in tqdm(range(2, max_k + 1), total=max_k - 1, desc=\"Iterating over possible K values\"):\n",
    "    kmeans_iter = KMeans(n_clusters=k, n_init=10, max_iter=100)\n",
    "    kmeans_iter.fit(df_performances)        \n",
    "    sil_list.append(silhouette_score(df_performances, kmeans_iter.labels_))\n",
    "    sse = kmeans_iter.inertia_\n",
    "    sse_list.append(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16cc2fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot indicators\n",
    "fig, axs = plt.subplots(2,1,figsize=(15,25))\n",
    "axs[0].plot(range(2, len(sse_list) + 2), sse_list)\n",
    "axs[0].set_ylabel('SSE', fontsize=22)\n",
    "axs[0].set_xlabel('K', fontsize=22)\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "axs[1].plot(range(2, len(sil_list) + 2), sil_list)\n",
    "axs[1].set_ylabel('Silhouette', fontsize=22)\n",
    "axs[1].set_xlabel('K', fontsize=22)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b766b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86149d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3917f3ba",
   "metadata": {},
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_performances.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters, n_init=10, max_iter=100)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(kmeans.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9737f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(kmeans.labels_, bins=range(0, len(set(kmeans.labels_)) + 1))\n",
    "dict(zip(bins, hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2ef95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracting labels\n",
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4114eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = \"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06fcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad90294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f495709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c35e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5582d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c12104e",
   "metadata": {},
   "source": [
    "## DBscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf71aa0",
   "metadata": {},
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48275f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(df_performances)\n",
    "scaled_dataframe = pd.DataFrame( scaled_array, columns = df_performances.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = scaled_dataframe, orient = \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19540d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe19c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.75, min_samples=5)\n",
    "dbscan.fit(scaled_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dbscan.labels_\n",
    "np.unique(dbscan.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6568527",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = labels\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = \"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf31874",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pdist(X=scaled_dataframe, metric='euclidean')  # pair-wise distance: how every record is far from all others\n",
    "dist = squareform(dist)                      # distance matrix given the vector dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafad21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin, kmax = 3, 50\n",
    "kth_distances = {}\n",
    "for k in range(kmin, kmax + 1): # initialize k lists\n",
    "    kth_distances[k] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83045abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dist:\n",
    "    # argsort returns the indexes that would sort d\n",
    "    index_kth_distance = np.argsort(d)[k]\n",
    "    for k in range(kmin, kmax + 1):\n",
    "        # append to kth_distances[k] the value in d that corresponds\n",
    "        # to the distance of the i-th point (record) from its k-th nn.\n",
    "        # it's like: kth_distances[k].append(sorted_d[k])), but we get \"sorted_d[k]\" by d[indexes_to_sort_d[k]]\n",
    "        kth_distances[k].append(d[index_kth_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5952f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 20))\n",
    "for k in kth_distances.keys():\n",
    "    plt.plot(range(0, len(kth_distances[k])), sorted(kth_distances[k]))\n",
    "    \n",
    "plt.ylabel('dist from k-th neighbor (eps)', fontsize=25)\n",
    "plt.xlabel('sorted distances', fontsize=25)\n",
    "#plt.ylim(top=5)\n",
    "plt.ylim(bottom=-0.25)\n",
    "plt.tick_params(axis='both', which='major', labelsize=25)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be54684",
   "metadata": {},
   "source": [
    "#### Grid search for eps and min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbcfb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(eps, min_samples, dataset, iter_):\n",
    "    # Fitting \n",
    "    dbscan_model_ = DBSCAN(eps = eps, min_samples = min_samples)\n",
    "    dbscan_model_.fit(dataset)\n",
    "    \n",
    "    # Mean Noise Point Distance metric\n",
    "    noise_indices = dbscan_model_.labels_ == -1\n",
    "    \n",
    "    if True in noise_indices:\n",
    "        neighboors = NearestNeighbors(n_neighbors = 6).fit(dataset)\n",
    "        distances, indices = neighboors.kneighbors(dataset)\n",
    "        noise_distances = distances[noise_indices, 1:]\n",
    "        noise_mean_distance = round(noise_distances.mean(), 3)\n",
    "    else:\n",
    "        noise_mean_distance = None\n",
    "    \n",
    "    # Number of found Clusters metric    \n",
    "    number_of_clusters = len(set(dbscan_model_.labels_[dbscan_model_.labels_ >= 0]))\n",
    "    \n",
    "    #print(\"%3d | Tested with eps = %3s and min_samples = %3s | %5s %4s\" % (i, eps, min_samples, str(noise_mean_distance), number_of_clusters))\n",
    "    \n",
    "    return(noise_mean_distance, number_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321050ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_to_test = [round(x, 3) for x in np.arange(0.4, 5, 0.3)] \n",
    "min_samples_to_test = np.arange(4, 30, 2)\n",
    "eps_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe per la metrica sulla distanza media dei noise points dai K punti più vicini\n",
    "results_noise = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    ")\n",
    "\n",
    "# Dataframe per la metrica sul numero di cluster\n",
    "results_clusters = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for eps in eps_to_test:\n",
    "    for min_samples in min_samples_to_test:\n",
    "        i += 1\n",
    "        # Calcolo le metriche\n",
    "        noise_metric, cluster_metric  = get_metrics(eps, min_samples, scaled_dataframe, i)\n",
    "        # Inserisco i risultati nei relativi dataframe\n",
    "        results_noise.loc[eps, min_samples] = noise_metric\n",
    "        results_clusters.loc[eps, min_samples] = cluster_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8) )\n",
    "\n",
    "sns.heatmap(results_noise, annot = True, ax = ax1, cbar = False).set_title(\"Mean Noise Points Distance\")\n",
    "sns.heatmap(results_clusters, annot = True, ax = ax2, cbar = False).set_title(\"Number of clusters\")\n",
    "\n",
    "ax1.set_xlabel(\"min_samples\")\n",
    "ax2.set_xlabel(\"min_samples\")\n",
    "ax1.set_ylabel(\"eps\")\n",
    "ax2.set_ylabel(\"eps\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70b01f",
   "metadata": {},
   "source": [
    "#### choose of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dbscan = DBSCAN(eps = 1, min_samples = 14)\n",
    "# Fitting\n",
    "best_dbscan.fit(scaled_dataframe)\n",
    "\n",
    "labels = best_dbscan.labels_\n",
    "np.unique(best_dbscan.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_dataframe[\"LABEL\"] = best_dbscan.labels_\n",
    "#sns.pairplot(data = scaled_dataframe, hue = \"LABEL\")\n",
    "\n",
    "# Extracting labels\n",
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = best_dbscan.labels_\n",
    "# Pairplot\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1cd77",
   "metadata": {},
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c121e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_array = scaler.fit_transform(df_performances)\n",
    "scaled_dataframe = pd.DataFrame( scaled_array, columns = df_performances.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.75, min_samples=5)\n",
    "dbscan.fit(scaled_dataframe)\n",
    "labels = dbscan.labels_\n",
    "np.unique(dbscan.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d44135",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = labels\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = \"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8178d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pdist(X=scaled_dataframe, metric='euclidean')  # pair-wise distance: how every record is far from all others\n",
    "dist = squareform(dist)                      # distance matrix given the vector dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin, kmax = 3, 50\n",
    "kth_distances = {}\n",
    "for k in range(kmin, kmax + 1): # initialize k lists\n",
    "    kth_distances[k] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dist:\n",
    "    # argsort returns the indexes that would sort d\n",
    "    index_kth_distance = np.argsort(d)[k]\n",
    "    for k in range(kmin, kmax + 1):\n",
    "        # append to kth_distances[k] the value in d that corresponds\n",
    "        # to the distance of the i-th point (record) from its k-th nn.\n",
    "        # it's like: kth_distances[k].append(sorted_d[k])), but we get \"sorted_d[k]\" by d[indexes_to_sort_d[k]]\n",
    "        kth_distances[k].append(d[index_kth_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57775ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 20))\n",
    "for k in kth_distances.keys():\n",
    "    plt.plot(range(0, len(kth_distances[k])), sorted(kth_distances[k]))\n",
    "    \n",
    "plt.ylabel('dist from k-th neighbor (eps)', fontsize=25)\n",
    "plt.xlabel('sorted distances', fontsize=25)\n",
    "#plt.ylim(top=5)\n",
    "plt.ylim(bottom=-0.25)\n",
    "plt.tick_params(axis='both', which='major', labelsize=25)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_to_test = [round(x, 3) for x in np.arange(0.2, 0.6, 0.1)]\n",
    "min_samples_to_test = np.arange(2, 30, 2)\n",
    "eps_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe per la metrica sulla distanza media dei noise points dai K punti più vicini\n",
    "results_noise = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    ")\n",
    "\n",
    "# Dataframe per la metrica sul numero di cluster\n",
    "results_clusters = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b86eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for eps in eps_to_test:\n",
    "    for min_samples in min_samples_to_test:\n",
    "        i += 1\n",
    "        # Calcolo le metriche\n",
    "        noise_metric, cluster_metric  = get_metrics(eps, min_samples, scaled_dataframe, i)\n",
    "        # Inserisco i risultati nei relativi dataframe\n",
    "        results_noise.loc[eps, min_samples] = noise_metric\n",
    "        results_clusters.loc[eps, min_samples] = cluster_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,4) )\n",
    "\n",
    "sns.heatmap(results_noise, annot = True, ax = ax1, cbar = False).set_title(\"Mean Noise Points Distance\")\n",
    "sns.heatmap(results_clusters, annot = True, ax = ax2, cbar = False).set_title(\"Number of clusters\")\n",
    "\n",
    "ax1.set_xlabel(\"min_samples\")\n",
    "ax2.set_xlabel(\"min_samples\")\n",
    "ax1.set_ylabel(\"eps\")\n",
    "ax2.set_ylabel(\"eps\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dbscan = DBSCAN(eps = 0.2, min_samples = 28)\n",
    "# Fitting\n",
    "best_dbscan.fit(scaled_dataframe)\n",
    "\n",
    "labels = best_dbscan.labels_\n",
    "np.unique(best_dbscan.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02063ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels\n",
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = best_dbscan.labels_\n",
    "# Pairplot\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = \"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f183c5c",
   "metadata": {},
   "source": [
    "# Hierachical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a7ed9",
   "metadata": {},
   "source": [
    "In this section we will see hierarchical clustering performed the divisive technique, in particular, using the four methods to compute the distances between clusters. To compute the distances has been used euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdf374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49117fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cluster_elements(data, threshold, criterion='distance'):\n",
    "    count = {}\n",
    "    clusters = fcluster(data, threshold, criterion)\n",
    "    for c in clusters:\n",
    "        count[c] = count[c]+1 if c in count else 1\n",
    "    return count, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['single', 'complete', 'average', 'ward']\n",
    "metrics = ['silhouette', 'davies_bouldin']\n",
    "evaluation_metrics = pd.DataFrame(index=methods, columns=metrics)\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62276e",
   "metadata": {},
   "source": [
    "Using scipy we can compute the linkage matrix and use it for the dendrogram plot. This is done for all the criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e962354",
   "metadata": {},
   "source": [
    "- ‘single’ uses the minimum of the distances between all observations of the two sets.\n",
    "\n",
    "- ‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.\n",
    "\n",
    "- ‘average’ uses the average of the distances of each observation of the two sets.\n",
    "\n",
    "- ‘ward’ minimizes the variance of the clusters being merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_array = scaler.fit_transform(df_performances)\n",
    "scaled_dataframe = pd.DataFrame( scaled_array, columns = df_performances.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    link = linkage(scaled_dataframe, method=method, metric = 'euclidean')\n",
    "    models[method] = link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a624f",
   "metadata": {},
   "source": [
    "Now plot the four dendrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797df81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=4, figsize=(32,7))\n",
    "i = 0\n",
    "for model in models.keys():\n",
    "    axs[i].set_title('Hierarchical Clustering by ' + model + ' Algorithm (' + methods[i] + '-linkage)')\n",
    "    axs[i].set_xlabel('Players or (Cluster Size)')\n",
    "    axs[i].set_ylabel('Distance')\n",
    "    dend = dendrogram(models[model],ax=axs[i],truncate_mode='lastp', p=25, leaf_rotation=60, leaf_font_size = 8, show_contracted=True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddbd8c",
   "metadata": {},
   "source": [
    "DA FINIRE -- Looking at the previews dendrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_threshold = {methods[0]:0.48, methods[1]:1.8,methods[2]:1,methods[3]:10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=4, figsize=(32,7))\n",
    "i = 0\n",
    "for model in models.keys():\n",
    "    axs[i].set_title('Hierarchical Clustering by ' + model + ' Algorithm (' + methods[i] + '-linkage)')\n",
    "    axs[i].set_xlabel('Players or (Cluster Size)')\n",
    "    axs[i].set_ylabel('Distance')\n",
    "    axs[i].axhline(y=cut_threshold[model], color=\"black\")\n",
    "    dend = dendrogram(models[model],ax=axs[i],truncate_mode='lastp', p=25, leaf_rotation=60, leaf_font_size = 8, show_contracted=True)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a849ffc",
   "metadata": {},
   "source": [
    "**Cluster evalution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e0ca2",
   "metadata": {},
   "source": [
    "Let's compute some metrics to evaluate the clustering quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "model_labels = {}\n",
    "for model in models.keys():\n",
    "    print(model)\n",
    "    count, clusters = count_cluster_elements(models[model], cut_threshold[model])\n",
    "    print(count)\n",
    "    \n",
    "    cluster = AgglomerativeClustering(n_clusters=len(count.keys()), affinity='euclidean', linkage=model)\n",
    "    cluster.fit_predict(scaled_dataframe)\n",
    "    labels = cluster.labels_\n",
    "    model_labels[model] = labels\n",
    "    davies_bouldin = davies_bouldin_score(scaled_dataframe, labels)\n",
    "    silhouette = silhouette_score(scaled_dataframe, labels, metric='euclidean')\n",
    "    evaluation_metrics.loc[model][metrics[0]] = silhouette\n",
    "    evaluation_metrics.loc[model][metrics[1]] = davies_bouldin\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f8ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "f, axs = plt.subplots(ncols=4, figsize=(32,7), sharey=True)\n",
    "for model in models.keys():\n",
    "    axs[i].set_title('Hierarchical Clustering by ' + model + ' Algorithm (' + methods[i] + '-linkage)')\n",
    "    axs[i].scatter(df_performances['nmatch'].values, df_performances['best_rank_points'].values, c=model_labels[model] , s=25, cmap='viridis')\n",
    "    axs[i].set_xlabel('nmatch')\n",
    "    axs[i].set_ylabel('best_rank_points')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0843c4",
   "metadata": {},
   "source": [
    "# XMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_initial_centers = 1   #number of clusters at the start. xmeans starts with only one cluster\n",
    "max_n_clusters = 20\n",
    "\n",
    "initial_centers = kmeans_plusplus_initializer(df_performances, amount_initial_centers).initialize()\n",
    "xmeans_instance = xmeans(df_performances, initial_centers, kmax=max_n_clusters)\n",
    "xmeans_instance.process(); #split with bayesian Information Criterion\n",
    "\n",
    "clusters = xmeans_instance.get_clusters();\n",
    "centers = xmeans_instance.get_centers()\n",
    "\n",
    "print([len(c) for c in clusters])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d14796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display allocated clusters\n",
    "visualizer = cluster_visualizer_multidim();\n",
    "visualizer.append_clusters(clusters, df_performances.values.tolist())\n",
    "visualizer.append_cluster(centers, None, marker = '*', markersize=5)\n",
    "#visualizer.show()\n",
    "visualizer.show(pair_filter=[[0, 1], [0, 2], [0, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bd541",
   "metadata": {},
   "source": [
    "**plot with sns library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(df_performances.shape[0],  dtype=int) #num of rows\n",
    "for i in range(len(clusters)):#number of cluster\n",
    "    for j in clusters[i]: #index of row of dataset in cluster i\n",
    "        labels[j] = int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_n = sns.color_palette(\"hls\", n_colors=len(clusters))\n",
    "palette_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dbe76c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracting labels\n",
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = labels\n",
    "# Pairplot\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = palette_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee02e53",
   "metadata": {},
   "source": [
    "# BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb5d22",
   "metadata": {},
   "source": [
    "<a href=\"https://pyclustering.github.io/docs/0.10.1/html/dc/d83/namespacepyclustering_1_1cluster_1_1birch.html\">BIRCH by PYCLUSTERING</a>\n",
    "<br />\n",
    "<a href=\"https://pyclustering.github.io/docs/0.10.1/html/d0/de3/citelist.html#CITEREF_article::birch::1\">BIRCH PAPER</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12fedf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df_performances.values.tolist()\n",
    " \n",
    "# Create BIRCH algorithm\n",
    "birch_instance = birch(data, 3, diameter=3)\n",
    " \n",
    "# Cluster analysis\n",
    "birch_instance.process()\n",
    " \n",
    "# Obtain results of clustering\n",
    "clusters = birch_instance.get_clusters()\n",
    "\n",
    "print([len(c) for c in clusters]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02011513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize obtained clusters in multi-dimensional space\n",
    "visualizer = cluster_visualizer_multidim()\n",
    "visualizer.append_clusters(clusters, data = df_performances.values.tolist())\n",
    "visualizer.show(pair_filter=[[0, 1], [0, 2], [0, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(df_performances.shape[0],  dtype=int) #num of rows\n",
    "for i in range(len(clusters)):#number of cluster\n",
    "    for j in clusters[i]: #index of row of dataset in cluster i\n",
    "        labels[j] = int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_n = sns.color_palette(\"hls\", n_colors=len(clusters))\n",
    "palette_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262aa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels\n",
    "cleaned_dataframe = df_performances.copy()\n",
    "cleaned_dataframe[\"LABEL\"] = labels\n",
    "# Pairplot\n",
    "sns.pairplot(data = cleaned_dataframe, hue = \"LABEL\", palette = palette_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ec3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
